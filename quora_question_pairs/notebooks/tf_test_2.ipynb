{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "dtypes ={\n",
    "    'id': np.uint32,\n",
    "    'qid1': np.uint32,\n",
    "    'qid2': np.uint32,\n",
    "    'question1': np.str,\n",
    "    'question2': np.str,\n",
    "    'is_duplicate': np.uint8\n",
    "}\n",
    "\n",
    "df_chunks = pd.read_csv('../../dataset/quora_train.csv.zip', dtype=dtypes, compression='zip',\n",
    "                 usecols=['question1', 'question2', 'is_duplicate'], iterator=True, chunksize=100)\n",
    "df_test = pd.read_csv('../../dataset/quora_train.csv.zip', dtype=dtypes, compression='zip',\n",
    "                 usecols=['question1', 'question2', 'is_duplicate'], nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_df(df):\n",
    "    def pad(v):\n",
    "        zeros = np.zeros([100, 300])\n",
    "        zeros[:v.shape[0],:v.shape[1]] = v\n",
    "        return zeros\n",
    "\n",
    "    def sorted_vec(doc):\n",
    "        t_list = [t for t in doc if not t.is_stop]\n",
    "        t_list = [t.vector for t in t_list]\n",
    "\n",
    "        return np.matrix(t_list)\n",
    "\n",
    "    q1s = df['question1'].map(nlp).map(sorted_vec).map(pad)\n",
    "    q2s = df['question1'].map(nlp).map(sorted_vec).map(pad)\n",
    "\n",
    "    q1m = np.concatenate(q1s.values).flatten().reshape([-1, 100, 300])\n",
    "    q2m = np.concatenate(q2s.values).flatten().reshape([-1, 100, 300])\n",
    "\n",
    "    labels = df['is_duplicate'].values\n",
    "\n",
    "    return q1m, q2m, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "def lstm_cell():\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(128)\n",
    "    return tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "\n",
    "def lstm_cell2():\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(128, reuse=True)\n",
    "    return tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "\n",
    "def length(sequence):\n",
    "    used = tf.sign(tf.reduce_max(tf.abs(sequence), reduction_indices=2))\n",
    "    length = tf.reduce_sum(used, reduction_indices=1)\n",
    "    length = tf.cast(length, tf.int32)\n",
    "    return length\n",
    "\n",
    "Q1 = tf.placeholder(tf.float32, shape=[None, 100, 300])\n",
    "Q2 = tf.placeholder(tf.float32, shape=[None, 100, 300])\n",
    "batch_size = tf.placeholder(tf.int32)\n",
    "is_dup = tf.placeholder(tf.uint8, shape=[None])\n",
    "dup_oh = tf.one_hot(is_dup, 2)\n",
    "\n",
    "cell1s = tf.contrib.rnn.MultiRNNCell([lstm_cell() for i in range(5)])\n",
    "cell2s = tf.contrib.rnn.MultiRNNCell([lstm_cell2() for i in range(5)])\n",
    "\n",
    "state = cell1s.zero_state(batch_size, dtype=tf.float32)\n",
    "\n",
    "outputs1, _1= tf.nn.dynamic_rnn(cell1s, Q1, sequence_length=length(Q1), initial_state=state)\n",
    "outputs2, _2= tf.nn.dynamic_rnn(cell2s, Q2, sequence_length=length(Q2), initial_state=state)\n",
    "\n",
    "outputs1 = tf.reshape(outputs1, [-1, 128])\n",
    "outputs2 = tf.reshape(outputs2, [-1, 128])\n",
    "\n",
    "sW = tf.get_variable(shape=[128, 128], initializer=tf.contrib.layers.xavier_initializer(), name='s-weight')\n",
    "sb = tf.get_variable(shape=[128], initializer=tf.contrib.layers.xavier_initializer(), name='s-bias')\n",
    "\n",
    "outputs1 = tf.nn.relu(tf.matmul(outputs1, sW) + sb)\n",
    "outputs1 = tf.reshape(outputs1, [-1, 100, 128])\n",
    "outputs1 = tf.nn.dropout(outputs1, keep_prob=keep_prob)\n",
    "\n",
    "outputs2 = tf.nn.relu(tf.matmul(outputs2, sW) + sb)\n",
    "outputs2 = tf.reshape(outputs2, [-1, 100, 128])\n",
    "outputs2 = tf.nn.dropout(outputs2, keep_prob=keep_prob)\n",
    "\n",
    "output11 = tf.reduce_mean(outputs1[:,0:25,:], 1)\n",
    "output12 = tf.reduce_mean(outputs1[:,26:50,:], 1)\n",
    "output13 = tf.reduce_mean(outputs1[:,51:75,:], 1)\n",
    "output14 = tf.reduce_mean(outputs1[:,76:100,:], 1)\n",
    "outputs1 = tf.concat([output11, output12, output13, output14], axis=1)\n",
    "\n",
    "output21 = tf.reduce_mean(outputs2[:,0:25,:], 1)\n",
    "output22 = tf.reduce_mean(outputs2[:,26:50,:], 1)\n",
    "output23 = tf.reduce_mean(outputs2[:,51:75,:], 1)\n",
    "output24 = tf.reduce_mean(outputs2[:,76:100,:], 1)\n",
    "outputs2 = tf.concat([output21, output22, output23, output24], axis=1)\n",
    "\n",
    "out = tf.concat([outputs1, outputs2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out = tf.nn.dropout(out, keep_prob=keep_prob)\n",
    "\n",
    "W1 = tf.get_variable(shape=[1024, 256], initializer=tf.contrib.layers.xavier_initializer(), name='weight1')\n",
    "b1 = tf.get_variable(shape=[256], initializer=tf.contrib.layers.xavier_initializer(), name='bias1')\n",
    "y1 = tf.nn.relu(tf.matmul(out, W1) + b1)\n",
    "y1 = tf.nn.dropout(y1, keep_prob=keep_prob)\n",
    "\n",
    "W2 = tf.get_variable(shape=[256, 2], initializer=tf.contrib.layers.xavier_initializer(), name='weight2')\n",
    "b2 = tf.get_variable(shape=[2], initializer=tf.contrib.layers.xavier_initializer(), name='bias2')\n",
    "y2 = tf.matmul(y1, W2) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.nn.softmax_cross_entropy_with_logits(logits=y2, labels=dup_oh)\n",
    "cost = tf.reduce_mean(cost)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.686211\n",
      "0.610931\n",
      "0.598988\n",
      "0.587054\n",
      "0.581664\n",
      "0.57768\n",
      "0.57812\n",
      "0.572426\n",
      "0.562285\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "test_q1m, test_q2m, test_labels = parse_df(df_test)\n",
    "test_dict = {Q1: test_q1m, Q2: test_q2m, is_dup: test_labels, keep_prob: 1.0, batch_size: test_q1m.shape[0]}\n",
    "\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    for df in df_chunks:\n",
    "        train_q1m, train_q2m, train_labels = parse_df(df)\n",
    "        train_dict = {Q1: train_q1m, Q2: train_q2m, is_dup: train_labels, keep_prob: 0.5, batch_size: train_q1m.shape[0]}\n",
    "\n",
    "        sess.run(optimizer, feed_dict=train_dict)\n",
    "\n",
    "        if count % 500 == 0:\n",
    "            print(sess.run(cost, feed_dict=test_dict))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variables_names =[v.name for v in tf.trainable_variables()]\n",
    "values = sess.run(variables_names)\n",
    "for k,v in zip(variables_names, values):\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat:0' shape=(?, 256) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_1:0' shape=(?, 64) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
