{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "%matplotlib inline\n",
    "from multiprocessing import Pool\n",
    "\n",
    "#from gensim.models import KeyedVectors\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "#keyedv= KeyedVectors.load_word2vec_format('../dataset/wiki.en.vec')\n",
    "\n",
    "dtypes ={\n",
    "    'id': np.uint32,\n",
    "    'qid1': np.uint32,\n",
    "    'qid2': np.uint32,\n",
    "    'question1': np.str,\n",
    "    'question2': np.str,\n",
    "    'is_duplicate': np.uint8\n",
    "}\n",
    "\n",
    "df = pd.read_csv('../../dataset/quora_train.csv', dtype=dtypes, usecols=['question1', 'question2', 'is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/ic/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/ic/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-2-b94d7a41dc95>\", line 2, in remove_parn\n    return re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", s)\nNameError: name 're' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b94d7a41dc95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremove_parn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremove_parn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ic/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         '''\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ic/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "def remove_parn(s):\n",
    "    return re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", s)\n",
    "\n",
    "pool = Pool()\n",
    "df['question1'] = pool.map(remove_parn, df['question1'])\n",
    "df['question2'] = pool.map(remove_parn, df['question2'])\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_noun(q1, q2):\n",
    "    q1 = q1 if type(q1) is str else ''\n",
    "    q2 = q2 if type(q2) is str else ''\n",
    "    \n",
    "    qt1 = [t for t in nlp(q1) if t.tag_.startswith('N')]\n",
    "    qt2 = [t for t in nlp(q2) if t.tag_.startswith('N')]\n",
    "    \n",
    "    count = 0\n",
    "    s_sum = 0\n",
    "    for t1 in qt1:\n",
    "        for t2 in qt2:\n",
    "            s_sum += t1.similarity(t2)\n",
    "            count += 1                  \n",
    "    \n",
    "    return s_sum / count if count != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pool = Pool()\n",
    "\n",
    "df['compare_noun'] = pool.starmap(compare_noun, tuple(zip(df.question1, df.question2)))\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_verb(q1, q2):\n",
    "    q1 = q1 if type(q1) is str else ''\n",
    "    q2 = q2 if type(q2) is str else ''\n",
    "    \n",
    "    qt1 = [t for t in nlp(q1) if t.tag_.startswith('V')]\n",
    "    qt2 = [t for t in nlp(q2) if t.tag_.startswith('V')]\n",
    "    \n",
    "    count = 0\n",
    "    s_sum = 0\n",
    "    for t1 in qt1:\n",
    "        for t2 in qt2:\n",
    "            s_sum += t1.similarity(t2)\n",
    "            count += 1                  \n",
    "    \n",
    "    return s_sum / count if count != 0 else 0\n",
    "\n",
    "df['compare_verb'] = pool.starmap(compare_verb, tuple(zip(df.question1, df.question2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_noun_max(q1, q2):\n",
    "    if len(q2) > len(q1):\n",
    "        q1, q2 = q2, q1\n",
    "    \n",
    "    q1 = q1 if type(q1) is str else ''\n",
    "    q2 = q2 if type(q2) is str else ''\n",
    "    \n",
    "    qt1 = [t for t in nlp(q1) if t.tag_.startswith('N')]\n",
    "    qt2 = [t for t in nlp(q2) if t.tag_.startswith('N')]\n",
    "    \n",
    "    s_sum = 0\n",
    "    for t1 in qt1:\n",
    "        s_sum = max([t1.similarity(t2) for t2 in qt2])\n",
    "               \n",
    "    \n",
    "    return s_sum / len(qt1) if len(qt1) != 0 else 0\n",
    "\n",
    "df['compare_noun_max'] = pool.starmap(compare_verb, tuple(zip(df.question1, df.question2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sml/.pyenv/versions/3.5.1/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/sml/.pyenv/versions/3.5.1/lib/python3.5/site-packages/sklearn/preprocessing/label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/sml/.pyenv/versions/3.5.1/lib/python3.5/site-packages/sklearn/preprocessing/label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "X = df[['compare_noun', 'compare_verb', 'compare_noun_max']]\n",
    "y = df[['is_duplicate']]\n",
    "\n",
    "gbm = xgb.XGBClassifier(max_depth=10, n_estimators=200).fit(X[:300000], y[:300000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "181it [34:50, 11.47s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "output = open('result.csv', 'w')\n",
    "output.write('test_id,is_duplicate\\n')\n",
    "\n",
    "df_test = pd.read_csv('../dataset/quora_test.csv', dtype=dtypes, iterator=True, chunksize=10000)\n",
    "\n",
    "for chunk in tqdm(df_test):\n",
    "    chunk['compare_noun'] = pool.starmap(compare_noun, tuple(zip(chunk.question1, chunk.question2)))\n",
    "    chunk['compare_verb'] = pool.starmap(compare_verb, tuple(zip(chunk.question1, chunk.question2)))\n",
    "    chunk['compare_noun_max'] = pool.starmap(compare_verb, tuple(zip(chunk.question1, chunk.question2)))\n",
    "    prediction = gbm.predict_proba(chunk[['compare_noun', 'compare_verb', 'compare_noun_max']])\n",
    "    \n",
    "    for i, p in zip(chunk['test_id'], prediction):\n",
    "        output.write('{},{}\\n'.format(i, p[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Score: 0.50479"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
