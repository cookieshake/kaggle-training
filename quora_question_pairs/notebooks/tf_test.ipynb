{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "dtypes ={\n",
    "    'id': np.uint32,\n",
    "    'qid1': np.uint32,\n",
    "    'qid2': np.uint32,\n",
    "    'question1': np.str,\n",
    "    'question2': np.str,\n",
    "    'is_duplicate': np.uint8\n",
    "}\n",
    "\n",
    "df = pd.read_csv('../../dataset/quora_train.csv.zip', dtype=dtypes, compression='zip', usecols=['question1', 'question2', 'is_duplicate'], nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(v):\n",
    "    zeros = np.zeros([100, 300])\n",
    "    zeros[:v.shape[0],:v.shape[1]] = v\n",
    "    return zeros\n",
    "    \n",
    "q1s = df['question1'].map(nlp).map(lambda x: np.matrix([t.vector for t in x])).map(pad)\n",
    "q2s = df['question1'].map(nlp).map(lambda x: np.matrix([t.vector for t in x])).map(pad)\n",
    "\n",
    "q1m = np.concatenate(q1s.values).flatten().reshape([-1, 100, 300])\n",
    "q2m = np.concatenate(q2s.values).flatten().reshape([-1, 100, 300])\n",
    "\n",
    "labels = df['is_duplicate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_q1m, test_q1m = q1m[:700], q1m[700:]\n",
    "train_q2m, test_q2m = q2m[:700], q2m[700:]\n",
    "train_labels, test_labels = labels[:700], labels[700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "Q1 = tf.placeholder(tf.float32, shape=[None, 100, 300])\n",
    "Q2 = tf.placeholder(tf.float32, shape=[None, 100, 300])\n",
    "is_dup = tf.placeholder(tf.uint8, shape=[None])\n",
    "dup_oh = tf.one_hot(is_dup, 2)\n",
    "\n",
    "cell1 = rnn.BasicLSTMCell(128, forget_bias=0.0)\n",
    "cell2 = rnn.BasicLSTMCell(128, forget_bias=0.0, reuse=True)\n",
    "\n",
    "state = cell1.zero_state(100, tf.float32)\n",
    "\n",
    "#Q1t = tf.transpose(Q1, [1, 0, 2])\n",
    "#Q2t = tf.transpose(Q2, [1, 0, 2])\n",
    "\n",
    "outputs1, _1= tf.nn.dynamic_rnn(cell1, Q1, initial_state=state, time_major=True)\n",
    "outputs2, _2= tf.nn.dynamic_rnn(cell2, Q2, initial_state=state, time_major=True)\n",
    "\n",
    "output1 = outputs1[:,-1,:]\n",
    "output2 = outputs2[:,-1,:]\n",
    "\n",
    "out = tf.concat([output1, output2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.get_variable(shape=[256, 256], initializer=tf.contrib.layers.xavier_initializer(), name='weight1')\n",
    "b1 = tf.get_variable(shape=[256], initializer=tf.contrib.layers.xavier_initializer(), name='bias1')\n",
    "y1 = tf.nn.relu(tf.matmul(out, W1) + b1)\n",
    "y1 = tf.nn.dropout(y1, keep_prob=keep_prob)\n",
    "\n",
    "W2 = tf.get_variable(shape=[256, 2], initializer=tf.contrib.layers.xavier_initializer(), name='weight2')\n",
    "b2 = tf.get_variable(shape=[2], initializer=tf.contrib.layers.xavier_initializer(), name='bias2')\n",
    "y2 = tf.matmul(y1, W2) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.nn.softmax_cross_entropy_with_logits(logits=y2, labels=dup_oh)\n",
    "cost = tf.reduce_mean(cost)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/10000 [00:02<6:29:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.712927 0.712064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  0%|          | 11/10000 [00:17<4:43:37,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.665561 0.666759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 21/10000 [00:32<4:40:03,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66393 0.665126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 31/10000 [00:48<4:57:55,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.663485 0.664577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 41/10000 [01:03<4:40:28,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.663228 0.664453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 51/10000 [01:19<4:40:07,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.666418 0.664422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 61/10000 [01:34<4:39:02,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.664651 0.664448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 71/10000 [01:49<4:40:21,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.662884 0.664477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 81/10000 [02:04<4:39:25,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.663949 0.664503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 91/10000 [02:20<4:38:50,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66166 0.664517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 101/10000 [02:35<4:39:03,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.664691 0.664556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 111/10000 [02:50<4:38:04,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.664181 0.6646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 121/10000 [03:05<4:40:44,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.662946 0.664644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 123/10000 [03:08<4:19:06,  1.57s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-0b1bf1fefa85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ic/.pyenv/versions/3.6.1/envs/ds/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ic/.pyenv/versions/3.6.1/envs/ds/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ic/.pyenv/versions/3.6.1/envs/ds/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ic/.pyenv/versions/3.6.1/envs/ds/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ic/.pyenv/versions/3.6.1/envs/ds/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_dict = {Q1: train_q1m, Q2: train_q2m, is_dup: train_labels, keep_prob: 0.7}\n",
    "test_dict = {Q1: test_q1m, Q2: test_q2m, is_dup: test_labels, keep_prob: 1.0}\n",
    "\n",
    "for i in tqdm(range(10000)):\n",
    "    sess.run(optimizer, feed_dict=train_dict)\n",
    "    if i % 10 == 0:\n",
    "        print(sess.run(cost, feed_dict=train_dict), sess.run(cost, feed_dict=test_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn/basic_lstm_cell/weights:0 [[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "rnn/basic_lstm_cell/biases:0 [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan]\n",
      "weight1:0 [[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "bias1:0 [ 0.04231776  0.04293922  0.05414493  0.05426981 -0.04333078  0.03259065\n",
      "  0.0344018   0.04202073 -0.09696482 -0.06271763  0.07334929  0.01098982\n",
      " -0.04711093 -0.08929223 -0.05968837 -0.05417346 -0.02101675 -0.02636659\n",
      " -0.09817353  0.05954519  0.04211203  0.095838    0.01382953 -0.08053321\n",
      " -0.01585892 -0.02605424 -0.00168175 -0.03579008  0.09973633 -0.08969726\n",
      " -0.04292193  0.06834041 -0.06455925 -0.02299754 -0.08260798 -0.09988731\n",
      "  0.08152313  0.04412825  0.08657653 -0.06606653 -0.1043638  -0.04912098\n",
      " -0.05718048  0.06660459  0.08968731 -0.0942672   0.07612201 -0.03218476\n",
      "  0.09735219 -0.01050805  0.01345863 -0.0138026   0.04016607  0.06522939\n",
      " -0.03624757  0.0763422  -0.02238774  0.06792814  0.06398372  0.00955326\n",
      " -0.00404877  0.10083886 -0.07098429 -0.1056566  -0.07332129  0.09098686\n",
      "  0.02877579  0.09148695  0.06419683 -0.0965452  -0.08720101 -0.07389922\n",
      "  0.03607068 -0.0820226  -0.10226734  0.00873984 -0.00419014 -0.0059018\n",
      "  0.02960326  0.02789594  0.09942948 -0.01113412  0.06002859 -0.00011589\n",
      "  0.06584747 -0.00911132  0.05942683 -0.01443584 -0.09472284 -0.10789514\n",
      "  0.01036711  0.05273749 -0.08385049 -0.07903899  0.07447163  0.04457892\n",
      " -0.06758814  0.07172646  0.00112026 -0.00623146  0.08836045 -0.09468606\n",
      "  0.03620026 -0.00152849  0.0737311  -0.08692066 -0.04245681 -0.00045051\n",
      "  0.06094946 -0.04638049  0.01253048 -0.02367003  0.10576566 -0.03259131\n",
      "  0.02311639 -0.0629482  -0.10632081 -0.06409915  0.0650716  -0.00295834\n",
      " -0.04672303  0.10773793  0.06786854  0.06793351  0.01961066 -0.07228787\n",
      " -0.02524614 -0.02059165 -0.03474665  0.0293755   0.03180361  0.08888019\n",
      " -0.03617157  0.0880295   0.02724462 -0.06305636  0.03316991 -0.08527897\n",
      " -0.10047698  0.0091787   0.08026045 -0.08460428 -0.01027259  0.03487137\n",
      "  0.0411628  -0.08620238  0.0414132  -0.08202637 -0.00597422  0.06333384\n",
      "  0.07313854 -0.10678931  0.10334862  0.06274047 -0.04940269  0.07946279\n",
      "  0.03717527 -0.07115455 -0.06246483 -0.00639787  0.03931375  0.03087746\n",
      " -0.08194254  0.02296595 -0.02779353 -0.03022221 -0.02328348 -0.02055673\n",
      " -0.06068975 -0.07244077  0.00092859 -0.08570699  0.09376581  0.06727517\n",
      " -0.01719183 -0.02822733  0.04312908  0.02291686  0.04199607  0.07116226\n",
      " -0.08647307  0.03412537  0.05381336 -0.01934959 -0.09094618  0.02961368\n",
      " -0.06829841 -0.01835582 -0.0551893  -0.08180854 -0.02104744  0.07992797\n",
      " -0.00696092  0.0007237  -0.0424267  -0.02223177 -0.03869368  0.02743933\n",
      " -0.00709698 -0.0724754  -0.07647055  0.08884986 -0.0041571  -0.01856069\n",
      "  0.06393199  0.06020835  0.02613643 -0.05665154 -0.01226793  0.02442532\n",
      "  0.08903191  0.07199405  0.06373354 -0.03897052  0.10112748 -0.01747202\n",
      " -0.05368979  0.07494485 -0.09082451  0.05394657  0.0572214   0.09840158\n",
      " -0.00191972 -0.09489987 -0.06823709  0.07153155 -0.05255104 -0.00630017\n",
      " -0.00945678 -0.1000797  -0.05790214  0.03026434 -0.02576133 -0.04002427\n",
      " -0.09136334 -0.034856   -0.02008723 -0.05653777  0.00366895  0.00080135\n",
      " -0.05146049 -0.03465296  0.04061671  0.02944234 -0.07148799  0.07399488\n",
      "  0.02847619 -0.08844572  0.04913615 -0.01101472 -0.04896289  0.09646363\n",
      " -0.00657344  0.04517979 -0.10470833 -0.10351036]\n",
      "weight2:0 [[-0.08879412  0.07892876]\n",
      " [ 0.01836333  0.07090914]\n",
      " [-0.02445914 -0.14380628]\n",
      " [-0.09776674 -0.0127039 ]\n",
      " [-0.1395423   0.00811577]\n",
      " [-0.09770288 -0.06312501]\n",
      " [ 0.01630379  0.07185667]\n",
      " [ 0.12467737 -0.10392267]\n",
      " [ 0.05545241 -0.0316412 ]\n",
      " [-0.09271092 -0.03944377]\n",
      " [-0.01276031 -0.14734618]\n",
      " [-0.07467194 -0.06155416]\n",
      " [ 0.1419003   0.13261583]\n",
      " [-0.06016305 -0.06551662]\n",
      " [-0.08470958  0.0683836 ]\n",
      " [ 0.12478471 -0.005301  ]\n",
      " [-0.0235122  -0.13526843]\n",
      " [-0.02077259 -0.10316177]\n",
      " [-0.10358855 -0.11570629]\n",
      " [-0.09666562  0.05287293]\n",
      " [-0.01256632  0.00580351]\n",
      " [-0.11432163 -0.09624313]\n",
      " [-0.03914727  0.10529981]\n",
      " [-0.03494208  0.14753047]\n",
      " [-0.03348239 -0.11123768]\n",
      " [ 0.00577137  0.01129265]\n",
      " [-0.12344538 -0.03330314]\n",
      " [ 0.04797511 -0.1282296 ]\n",
      " [ 0.02347928 -0.10186136]\n",
      " [ 0.14412251  0.15109798]\n",
      " [-0.00795221 -0.02852902]\n",
      " [ 0.06200239 -0.04489154]\n",
      " [ 0.00318708  0.05822682]\n",
      " [-0.00332582 -0.0665099 ]\n",
      " [ 0.02307498 -0.06116378]\n",
      " [ 0.13033876  0.02253619]\n",
      " [-0.06813619 -0.09880467]\n",
      " [ 0.09050719 -0.11541287]\n",
      " [-0.11285537 -0.11485278]\n",
      " [ 0.06532879  0.03578974]\n",
      " [-0.05437671  0.10624227]\n",
      " [ 0.1175611  -0.07008616]\n",
      " [ 0.09194827 -0.00988479]\n",
      " [ 0.05768869 -0.1505173 ]\n",
      " [-0.1139162   0.09068809]\n",
      " [ 0.08590287  0.12669045]\n",
      " [ 0.11881139 -0.13722558]\n",
      " [ 0.08613577 -0.01776378]\n",
      " [ 0.14024928 -0.07992182]\n",
      " [ 0.03041224  0.05423775]\n",
      " [-0.00628251  0.13813789]\n",
      " [ 0.07047655  0.00926869]\n",
      " [ 0.0898514   0.12283187]\n",
      " [ 0.08327432  0.00642579]\n",
      " [-0.04734065  0.1003494 ]\n",
      " [ 0.10956103 -0.13539961]\n",
      " [-0.13100655 -0.10808635]\n",
      " [ 0.14490759 -0.11731599]\n",
      " [ 0.06261467  0.05438114]\n",
      " [ 0.12009235  0.09060518]\n",
      " [ 0.04352678 -0.06514548]\n",
      " [ 0.15890355 -0.0842751 ]\n",
      " [-0.11539971  0.12723786]\n",
      " [-0.01360244  0.10161087]\n",
      " [ 0.06760532 -0.03213811]\n",
      " [-0.10421004  0.06487135]\n",
      " [-0.10445146 -0.04488678]\n",
      " [-0.05218539  0.12598374]\n",
      " [ 0.00268782  0.01298317]\n",
      " [ 0.04144555  0.0912036 ]\n",
      " [ 0.01880468  0.10975328]\n",
      " [-0.00943409  0.00409585]\n",
      " [ 0.04038369 -0.14442791]\n",
      " [ 0.13782814 -0.12463699]\n",
      " [ 0.06425463  0.04693148]\n",
      " [-0.04487548  0.08403185]\n",
      " [-0.06085292  0.0076371 ]\n",
      " [-0.14222905  0.0439724 ]\n",
      " [-0.06945807 -0.03405884]\n",
      " [ 0.14694534  0.08446228]\n",
      " [ 0.0632872   0.07817568]\n",
      " [-0.0559876  -0.01058687]\n",
      " [ 0.00851597  0.0123377 ]\n",
      " [ 0.10921001  0.11788476]\n",
      " [-0.06213082  0.0124874 ]\n",
      " [-0.11693884  0.10829803]\n",
      " [ 0.04883064 -0.12057526]\n",
      " [ 0.04174471 -0.03118385]\n",
      " [ 0.14299181 -0.08868386]\n",
      " [-0.0109794   0.05300286]\n",
      " [ 0.14469105  0.09444033]\n",
      " [ 0.11281675 -0.03181769]\n",
      " [ 0.06165905  0.07871003]\n",
      " [-0.07948413 -0.10269988]\n",
      " [-0.09704176 -0.0400677 ]\n",
      " [ 0.13190927 -0.06021113]\n",
      " [ 0.10746741 -0.05148432]\n",
      " [-0.08586209  0.03434872]\n",
      " [-0.07423826  0.04101055]\n",
      " [ 0.14870009  0.05156921]\n",
      " [ 0.08446883  0.00468046]\n",
      " [-0.1335638   0.03302439]\n",
      " [-0.01012238  0.08430368]\n",
      " [ 0.04495451 -0.06140793]\n",
      " [ 0.05246463 -0.08157409]\n",
      " [-0.122751   -0.14865239]\n",
      " [ 0.00400838 -0.00869514]\n",
      " [-0.13441887 -0.10463668]\n",
      " [ 0.05493807  0.08317973]\n",
      " [-0.10547122  0.0921305 ]\n",
      " [-0.10443085 -0.14262934]\n",
      " [-0.12260728 -0.04533686]\n",
      " [ 0.13316289  0.03417491]\n",
      " [-0.08393638 -0.00633641]\n",
      " [ 0.14045669  0.04308227]\n",
      " [ 0.04113236  0.05914494]\n",
      " [ 0.03717008  0.12354931]\n",
      " [-0.02057393  0.04102717]\n",
      " [-0.11934344  0.0354328 ]\n",
      " [-0.03341065 -0.14864123]\n",
      " [ 0.08408704  0.02949248]\n",
      " [ 0.10043907 -0.11756326]\n",
      " [-0.09253208 -0.12646548]\n",
      " [-0.00972297  0.14042391]\n",
      " [ 0.0116035  -0.00509053]\n",
      " [-0.03111117  0.06615849]\n",
      " [-0.11646312 -0.14301929]\n",
      " [-0.13164935 -0.09637226]\n",
      " [-0.13118151 -0.02088036]\n",
      " [-0.12042141 -0.11616474]\n",
      " [-0.04703781  0.14147587]\n",
      " [ 0.11842053  0.12853642]\n",
      " [ 0.02972493 -0.13146354]\n",
      " [ 0.15294968 -0.0389136 ]\n",
      " [-0.02111486  0.06702612]\n",
      " [ 0.11319122 -0.05810803]\n",
      " [-0.08899713 -0.03986424]\n",
      " [ 0.14909968 -0.11564557]\n",
      " [-0.14494248  0.15005335]\n",
      " [-0.0604347  -0.10501385]\n",
      " [ 0.05426285 -0.13233419]\n",
      " [-0.10079163 -0.03835527]\n",
      " [ 0.10750476 -0.1025816 ]\n",
      " [ 0.11482092 -0.00566731]\n",
      " [-0.0605139  -0.12414071]\n",
      " [-0.05435566  0.04988247]\n",
      " [ 0.03541888  0.01904005]\n",
      " [ 0.12817189 -0.00812292]\n",
      " [ 0.09978217  0.11150002]\n",
      " [ 0.01407311 -0.13272329]\n",
      " [-0.07706761  0.03793323]\n",
      " [ 0.07455833 -0.00610143]\n",
      " [ 0.13049892  0.02790633]\n",
      " [-0.1137237   0.03302096]\n",
      " [ 0.03874627  0.08427677]\n",
      " [-0.05420018  0.08645141]\n",
      " [-0.02220224  0.11018282]\n",
      " [-0.12826204  0.07836208]\n",
      " [ 0.00097314 -0.12613983]\n",
      " [-0.02530851  0.13211574]\n",
      " [-0.00749804  0.05217589]\n",
      " [ 0.15488063  0.00714177]\n",
      " [-0.10732438  0.10804734]\n",
      " [ 0.06109603 -0.02799555]\n",
      " [ 0.13762507  0.0915385 ]\n",
      " [ 0.01690209  0.11295366]\n",
      " [-0.07358639  0.07180941]\n",
      " [ 0.01070522  0.12546161]\n",
      " [ 0.07280108  0.01304103]\n",
      " [ 0.08899163 -0.12861933]\n",
      " [-0.06821392 -0.0786872 ]\n",
      " [-0.1028489  -0.13915755]\n",
      " [-0.11151317 -0.02112423]\n",
      " [ 0.012114   -0.04212202]\n",
      " [ 0.05204922 -0.03246755]\n",
      " [ 0.0376474   0.07627448]\n",
      " [ 0.07051329 -0.08534453]\n",
      " [-0.04627975  0.00534016]\n",
      " [ 0.01235245  0.07496934]\n",
      " [ 0.13196021 -0.07291088]\n",
      " [ 0.03056154  0.01987301]\n",
      " [ 0.00895407  0.041431  ]\n",
      " [ 0.01191001 -0.00952786]\n",
      " [-0.07233439  0.03409867]\n",
      " [-0.13013639  0.00332204]\n",
      " [ 0.05423662 -0.03676713]\n",
      " [-0.04736788  0.10191363]\n",
      " [ 0.12374479 -0.0383793 ]\n",
      " [-0.08130442 -0.12859054]\n",
      " [-0.07816258 -0.02620994]\n",
      " [ 0.15147519  0.03453963]\n",
      " [-0.00729092  0.14067623]\n",
      " [-0.12100291  0.02477056]\n",
      " [ 0.05814672  0.07960743]\n",
      " [-0.0837146  -0.14748259]\n",
      " [ 0.08336751  0.01833279]\n",
      " [-0.09366541  0.12728214]\n",
      " [ 0.02237023  0.03982313]\n",
      " [ 0.05999772  0.13088875]\n",
      " [-0.05626095  0.12284765]\n",
      " [ 0.0645048   0.01971851]\n",
      " [ 0.15543929 -0.15183677]\n",
      " [ 0.05443147  0.02854887]\n",
      " [-0.00244598 -0.00596952]\n",
      " [ 0.10120338  0.11029436]\n",
      " [ 0.12338234  0.03590438]\n",
      " [-0.04613934  0.02819099]\n",
      " [ 0.10912347  0.1301555 ]\n",
      " [-0.00049549 -0.14529897]\n",
      " [-0.04065971 -0.05063145]\n",
      " [-0.04147125 -0.03266149]\n",
      " [-0.11241516 -0.06896328]\n",
      " [-0.09989172  0.05704065]\n",
      " [-0.06847944 -0.0817328 ]\n",
      " [ 0.13503692 -0.13816899]\n",
      " [-0.10103105 -0.09989074]\n",
      " [ 0.11491254 -0.00978109]\n",
      " [-0.14241834 -0.02664447]\n",
      " [ 0.05704647 -0.10372205]\n",
      " [-0.11010331 -0.10372365]\n",
      " [ 0.10588118  0.04084891]\n",
      " [ 0.09318658 -0.10515354]\n",
      " [ 0.05207126 -0.09214151]\n",
      " [-0.05183431  0.00584765]\n",
      " [-0.04468401  0.04512686]\n",
      " [-0.10499368  0.07304748]\n",
      " [-0.08588614 -0.01317945]\n",
      " [-0.1424115   0.12922281]\n",
      " [ 0.12512594 -0.08876966]\n",
      " [-0.15205646  0.07786676]\n",
      " [ 0.00553147 -0.07672493]\n",
      " [ 0.00273196  0.04141427]\n",
      " [ 0.0587146  -0.10913572]\n",
      " [-0.06249138  0.01514219]\n",
      " [-0.1199086  -0.05999148]\n",
      " [-0.08630805 -0.04048365]\n",
      " [ 0.03675652 -0.11739939]\n",
      " [-0.01164369 -0.05260641]\n",
      " [ 0.02739323  0.0978398 ]\n",
      " [-0.05269317  0.00391156]\n",
      " [ 0.04454155 -0.00232036]\n",
      " [ 0.07442456  0.0506016 ]\n",
      " [-0.10743177  0.02775127]\n",
      " [ 0.07298834  0.00787765]\n",
      " [-0.01599374  0.08466111]\n",
      " [ 0.15421371 -0.07820884]\n",
      " [ 0.0784974  -0.04053183]\n",
      " [ 0.05486321  0.09538966]\n",
      " [-0.01859952  0.03795936]\n",
      " [ 0.09672312  0.06169429]\n",
      " [-0.09577274  0.10630193]\n",
      " [ 0.14337437  0.12667279]\n",
      " [ 0.0449283   0.13504177]\n",
      " [ 0.15912522  0.09557107]\n",
      " [-0.12743208  0.00484288]\n",
      " [-0.13628781 -0.00888547]]\n",
      "bias2:0 [ 0.59986579  0.9909147 ]\n"
     ]
    }
   ],
   "source": [
    "variables_names =[v.name for v in tf.trainable_variables()]\n",
    "values = sess.run(variables_names)\n",
    "for k,v in zip(variables_names, values):\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'BasicLSTMCellZeroState/zeros:0' shape=(100, 128) dtype=float32>, h=<tf.Tensor 'BasicLSTMCellZeroState/zeros_1:0' shape=(100, 128) dtype=float32>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rnn/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, 100, 256) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
